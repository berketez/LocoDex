import chalk from 'chalk';
import ora from 'ora';
import { exec, spawn } from 'child_process';
import { promisify } from 'util';
import * as fs from 'fs';
import * as path from 'path';
import * as os from 'os';

const execAsync = promisify(exec);

export class AgentManager {
  private conversationContext: Array<{role: string, content: string, tokens?: number}> = [];
  private totalTokens = 0;
  private readonly MAX_CONTEXT_LENGTH = 128000;
  private selectedModel: string = '';

  constructor() {}

  async start(model?: string): Promise<void> {
    console.log(chalk.cyan('ğŸ¤– LocoDex AI Agent BaÅŸlatÄ±lÄ±yor...\n'));

    // Model seÃ§imi
    if (!model) {
      this.selectedModel = await this.selectModel();
    } else {
      this.selectedModel = model;
    }

    console.log(chalk.green(`âœ“ AI Agent hazÄ±r: ${this.selectedModel}`));
    console.log(chalk.cyan('\nğŸ¤– Merhaba! Ben LocoDex AI Agent\'Ä±nÄ±zÄ±m.'));
    console.log(chalk.gray('ğŸ’¬ Benimle sohbet edebilir, terminal komutlarÄ± Ã§alÄ±ÅŸtÄ±rabiliriz.'));
    console.log(chalk.gray('ğŸ’¡ Ã–rnekler:'));
    console.log(chalk.gray('   â€¢ "ls komutu Ã§alÄ±ÅŸtÄ±r"'));
    console.log(chalk.gray('   â€¢ "package.json dosyasÄ±nÄ± oku"'));
    console.log(chalk.gray('   â€¢ "Python calculator kod yaz"'));
    console.log(chalk.gray('   â€¢ "git status kontrol et"'));
    console.log(chalk.gray('ğŸ“ Ã‡Ä±kÄ±ÅŸ: "exit" yazÄ±n\n'));

    // Agent chat loop
    await this.startAgentChat();
  }

  private async startAgentChat(): Promise<void> {
    const prompt = require('prompt-sync')({ sigint: true });

    while (true) {
      try {
        // Context bilgisi gÃ¶ster
        if (this.conversationContext.length > 0) {
          this.displayContextInfo();
        }

        const input = prompt(chalk.cyan('ğŸ‘¤ Sen: '));
        
        if (!input || input.toLowerCase().trim() === 'exit') {
          console.log(chalk.green('ğŸ‘‹ Agent kapatÄ±lÄ±yor...'));
          break;
        }

        if (!input.trim()) {
          continue;
        }

        // Agent'a gÃ¶nder ve yanÄ±t al
        const response = await this.processAgentRequest(input);
        console.log(chalk.green('ğŸ¤– Agent: ') + response + '\n');

      } catch (error) {
        if (error instanceof Error && error.message === 'canceled') {
          console.log(chalk.green('\nğŸ‘‹ Agent kapatÄ±lÄ±yor...'));
          break;
        }
        console.log(chalk.red(`âŒ Agent hatasÄ±: ${error}`));
      }
    }
  }

  private async processAgentRequest(input: string): Promise<string> {
    const thinking = ora('AI Agent dÃ¼ÅŸÃ¼nÃ¼yor...').start();
    
    try {
      let systemResponse = '';
      
      // Terminal komut tespit etme
      if (this.isTerminalRequest(input)) {
        const command = this.extractCommand(input);
        if (command) {
          systemResponse += await this.executeTerminalCommand(command);
        }
      }

      // Dosya operasyonlarÄ±
      if (this.isFileRequest(input)) {
        const fileOp = await this.handleFileOperation(input);
        systemResponse += fileOp;
      }

      // Context gÃ¼ncelle
      this.updateContext('user', input + systemResponse);

      thinking.stop();

      // AI'ya gÃ¶nder
      const aiResponse = await this.getAIResponse(input, systemResponse);
      this.updateContext('assistant', aiResponse);

      // Kod oluÅŸturma kontrolÃ¼
      await this.handleCodeGeneration(aiResponse, input);

      return systemResponse + aiResponse;

    } catch (error) {
      thinking.stop();
      throw error;
    }
  }

  private isTerminalRequest(input: string): boolean {
    const terminalKeywords = [
      'komut Ã§alÄ±ÅŸtÄ±r', 'run command', 'execute',
      'ls', 'pwd', 'git', 'npm', 'node', 'python',
      'terminal', 'bash', 'shell', 'Ã§alÄ±ÅŸtÄ±r'
    ];
    
    const lowerInput = input.toLowerCase();
    return terminalKeywords.some(keyword => lowerInput.includes(keyword));
  }

  private extractCommand(input: string): string | null {
    // Ã‡eÅŸitli command extraction patterns
    const patterns = [
      /"([^"]+)"/,           // "command"
      /'([^']+)'/,           // 'command'
      /`([^`]+)`/,           // `command`
      /Ã§alÄ±ÅŸtÄ±r\s+(.+)/i,    // Ã§alÄ±ÅŸtÄ±r command
      /run\s+(.+)/i,         // run command
      /execute\s+(.+)/i      // execute command
    ];

    for (const pattern of patterns) {
      const match = input.match(pattern);
      if (match) {
        return match[1].trim();
      }
    }

    // Basit komutlarÄ± direkt tespit et
    const simpleCommands = ['ls', 'pwd', 'git status', 'npm --version', 'node --version', 'python --version'];
    const lowerInput = input.toLowerCase();
    
    for (const cmd of simpleCommands) {
      if (lowerInput.includes(cmd)) {
        return cmd;
      }
    }

    return null;
  }

  private async executeTerminalCommand(command: string): Promise<string> {
    console.log(chalk.yellow(`ğŸ–¥ï¸  Terminal: ${command}`));

    // GÃ¼venlik kontrolÃ¼
    if (this.isUnsafeCommand(command)) {
      return '\nğŸš« GÃ¼venlik nedeniyle bu komut Ã§alÄ±ÅŸtÄ±rÄ±lamaz.\n';
    }

    try {
      const { stdout, stderr } = await execAsync(command, { 
        timeout: 30000,
        maxBuffer: 1024 * 1024 
      });

      let result = '\nğŸ“¤ Terminal Ã‡Ä±ktÄ±sÄ±:\n';
      if (stdout) result += `${stdout}`;
      if (stderr) result += `âš ï¸ UyarÄ±: ${stderr}`;
      result += '\n';

      return result;

    } catch (error: any) {
      return `\nâŒ Terminal HatasÄ±: ${error.message}\n`;
    }
  }

  private isUnsafeCommand(command: string): boolean {
    const unsafePatterns = [
      /\brm\s+-rf/, /\brm\s+[^-]/, /\bsudo\b/, /\bchmod\s+\+x/,
      /curl.*\|\s*sh/, /wget.*\|\s*sh/, /\>\s*\/dev\/sd/,
      /\bdd\s+if=/, /\bmkfs\b/, /\bformat\b/, /\bfdisk\b/,
      /\breboot\b/, /\bshutdown\b/, /\bkill\s+-9/, /\bpkill\b/
    ];

    return unsafePatterns.some(pattern => pattern.test(command));
  }

  private isFileRequest(input: string): boolean {
    const fileKeywords = [
      'dosya oku', 'read file', 'dosya yaz', 'write file',
      'dosya listele', 'list files', 'dizin', 'directory'
    ];
    
    const lowerInput = input.toLowerCase();
    return fileKeywords.some(keyword => lowerInput.includes(keyword));
  }

  private async handleFileOperation(input: string): Promise<string> {
    const lowerInput = input.toLowerCase();

    try {
      // Dosya okuma
      if (lowerInput.includes('oku') || lowerInput.includes('read')) {
        const fileMatch = input.match(/["']([^"']+)["']|(\S+\.\w+)/);
        if (fileMatch) {
          const fileName = fileMatch[1] || fileMatch[2];
          const content = await this.readFile(fileName);
          return `\nğŸ“ Dosya Ä°Ã§eriÄŸi (${fileName}):\n\`\`\`\n${content.substring(0, 1000)}${content.length > 1000 ? '...' : ''}\n\`\`\`\n`;
        }
      }

      // Dizin listeleme
      if (lowerInput.includes('listele') || lowerInput.includes('list')) {
        const files = await this.listDirectory();
        return `\nğŸ“‚ Dizin Ä°Ã§eriÄŸi:\n${files.join('\n')}\n`;
      }

    } catch (error) {
      return `\nâŒ Dosya iÅŸlemi hatasÄ±: ${error instanceof Error ? error.message : error}\n`;
    }

    return '';
  }

  private async readFile(filePath: string): Promise<string> {
    const fullPath = path.resolve(filePath);
    if (!fs.existsSync(fullPath)) {
      throw new Error(`Dosya bulunamadÄ±: ${filePath}`);
    }
    
    const stats = fs.statSync(fullPath);
    if (stats.size > 1024 * 1024) {
      throw new Error(`Dosya Ã§ok bÃ¼yÃ¼k: ${(stats.size / 1024 / 1024).toFixed(1)}MB`);
    }
    
    return fs.readFileSync(fullPath, 'utf-8');
  }

  private async listDirectory(dirPath: string = '.'): Promise<string[]> {
    const fullPath = path.resolve(dirPath);
    const items = fs.readdirSync(fullPath);
    
    return items.map(item => {
      const itemPath = path.join(fullPath, item);
      const stats = fs.statSync(itemPath);
      const icon = stats.isDirectory() ? 'ğŸ“' : 'ğŸ“„';
      const size = stats.isFile() ? ` (${stats.size} bytes)` : '';
      return `${icon} ${item}${size}`;
    });
  }

  private async getAIResponse(input: string, systemResponse: string): Promise<string> {
    try {
      // Ã–nce LocoDex AI Agent servisini dene (Docker)
      const agentResponse = await fetch('http://localhost:3001/api/chat/completions', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          model: this.selectedModel,
          messages: [
            {
              role: 'system',
              content: `Sen LocoDex AI Agent'Ä±sÄ±n. Terminal komutlarÄ± Ã§alÄ±ÅŸtÄ±rabilir, dosya okuyabilir, kod yazabilirsin. KÄ±sa ve pratik yanÄ±tlar ver. Markdown kod bloklarÄ± kullan. Sistem Ã§Ä±ktÄ±sÄ±: ${systemResponse}`
            },
            ...this.conversationContext.slice(-10)
          ],
          temperature: 0.3,
          max_tokens: 1500,
          stream: false
        })
      });

      if (agentResponse.ok) {
        const data = await agentResponse.json();
        return data.choices[0]?.message?.content || 'YanÄ±t alÄ±namadÄ±.';
      }

      // Fallback: Direkt LM Studio
      console.log(chalk.yellow('ğŸ”„ AI Agent servisine ulaÅŸÄ±lamadÄ±, direkt LM Studio kullanÄ±lÄ±yor...'));
      
      const directResponse = await fetch('http://localhost:1234/v1/chat/completions', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          model: this.selectedModel,
          messages: [
            {
              role: 'system',
              content: `Sen LocoDex AI Agent'Ä±sÄ±n. Terminal komutlarÄ± Ã§alÄ±ÅŸtÄ±rabilir, dosya okuyabilir, kod yazabilirsin. KÄ±sa ve pratik yanÄ±tlar ver. Markdown kod bloklarÄ± kullan.`
            },
            ...this.conversationContext.slice(-10)
          ],
          temperature: 0.3,
          max_tokens: 1500,
          stream: false
        })
      });

      if (directResponse.ok) {
        const data = await directResponse.json();
        return data.choices[0]?.message?.content || 'YanÄ±t alÄ±namadÄ±.';
      } else {
        return 'AI servislerine baÄŸlanÄ±lamadÄ±. Docker ve LM Studio kontrol edin.';
      }

    } catch (error) {
      return `BaÄŸlantÄ± hatasÄ±: ${error instanceof Error ? error.message : error}`;
    }
  }

  private async handleCodeGeneration(aiResponse: string, userInput: string): Promise<void> {
    const codeBlocks = aiResponse.match(/```(\w+)?\n([\s\S]*?)\n```/g);
    if (!codeBlocks) return;

    console.log(chalk.blue(`ğŸ” ${codeBlocks.length} kod bloÄŸu bulundu!`));

    for (let i = 0; i < codeBlocks.length; i++) {
      const block = codeBlocks[i];
      const match = block.match(/```(\w+)?\n([\s\S]*?)\n```/);
      if (!match) continue;

      const language = match[1] || 'txt';
      const code = match[2].trim();
      if (!code) continue;

      // Dosya adÄ± oluÅŸtur
      const filename = this.generateFilename(userInput, language);
      const desktopPath = path.join(os.homedir(), 'Desktop');
      const fullPath = path.join(desktopPath, filename);

      try {
        fs.writeFileSync(fullPath, code, 'utf-8');
        console.log(chalk.green(`ğŸ“ Kod dosyasÄ± oluÅŸturuldu: ${filename}`));
        
        // Ã‡alÄ±ÅŸtÄ±rma Ã¶nerisi
        if (this.shouldAutoExecute(userInput, language)) {
          console.log(chalk.yellow(`ğŸ’¡ Ã‡alÄ±ÅŸtÄ±rmak iÃ§in: "${this.getRunCommand(language, filename)}"`));
        }

      } catch (error) {
        console.log(chalk.red(`âŒ Dosya oluÅŸturma hatasÄ±: ${error}`));
      }
    }
  }

  private generateFilename(userInput: string, language: string): string {
    const lowerInput = userInput.toLowerCase();
    let baseName = 'agent_code';
    
    if (lowerInput.includes('calculator')) baseName = 'calculator';
    else if (lowerInput.includes('game')) baseName = 'game';
    else if (lowerInput.includes('server')) baseName = 'server';
    else if (lowerInput.includes('bot')) baseName = 'bot';
    else if (lowerInput.includes('api')) baseName = 'api';
    
    const extension = this.getFileExtension(language);
    const timestamp = Date.now().toString().slice(-6);
    
    return `${baseName}_${timestamp}.${extension}`;
  }

  private shouldAutoExecute(userInput: string, language: string): boolean {
    const executeKeywords = ['Ã§alÄ±ÅŸtÄ±r', 'run', 'execute', 'test', 'dene'];
    const hasExecuteKeyword = executeKeywords.some(keyword => 
      userInput.toLowerCase().includes(keyword)
    );
    
    return hasExecuteKeyword && ['python', 'javascript'].includes(language);
  }

  private getFileExtension(language: string): string {
    const extensions: Record<string, string> = {
      python: 'py', javascript: 'js', typescript: 'ts',
      html: 'html', css: 'css', json: 'json', shell: 'sh', bash: 'sh'
    };
    return extensions[language] || 'txt';
  }

  private getRunCommand(language: string, filename: string): string {
    const commands: Record<string, string> = {
      python: `python3 ${filename}`,
      javascript: `node ${filename}`,
      shell: `bash ${filename}`,
      bash: `bash ${filename}`
    };
    return commands[language] || `open ${filename}`;
  }

  private async selectModel(): Promise<string> {
    const models = await this.discoverModels();
    
    if (models.length === 0) {
      console.log(chalk.red('âŒ HiÃ§ model bulunamadÄ±!'));
      console.log(chalk.yellow('âš ï¸  LÃ¼tfen LM Studio\'yu baÅŸlatÄ±n ve model indirin.'));
      process.exit(1);
    }

    console.log(chalk.cyan('\nğŸ¤– Mevcut AI Modelleri:'));
    models.forEach((model, index) => {
      const icon = model.provider === 'Ollama' ? 'ğŸ¦™' : 'ğŸ¬';
      console.log(chalk.green(`  ${index + 1}. ${icon} ${model.name} (${model.provider})`));
    });

    const prompt = require('prompt-sync')({ sigint: true });
    const answer = prompt(chalk.cyan('\nKullanmak istediÄŸiniz modelin numarasÄ±nÄ± seÃ§in (enter = 1): '));
    
    const index = answer.trim() === '' ? 0 : parseInt(answer) - 1;
    if (index >= 0 && index < models.length) {
      console.log(chalk.green(`âœ“ ${models[index].name} modeli seÃ§ildi!`));
      return models[index].name;
    } else {
      console.log(chalk.yellow('GeÃ§ersiz seÃ§im, ilk model kullanÄ±lÄ±yor.'));
      return models[0].name;
    }
  }

  private async discoverModels(): Promise<Array<{name: string, provider: string}>> {
    const models: Array<{name: string, provider: string}> = [];
    
    try {
      // LM Studio check
      const lmResponse = await fetch('http://localhost:1234/v1/models');
      if (lmResponse.ok) {
        const data = await lmResponse.json();
        data.data?.forEach((model: any) => {
          models.push({ name: model.id, provider: 'LM Studio' });
        });
      }
    } catch (e) {
      // LM Studio not available
    }

    try {
      // Ollama check
      const ollamaResponse = await fetch('http://localhost:11434/api/tags');
      if (ollamaResponse.ok) {
        const data = await ollamaResponse.json();
        data.models?.forEach((model: any) => {
          models.push({ name: model.name, provider: 'Ollama' });
        });
      }
    } catch (e) {
      // Ollama not available
    }

    return models;
  }

  private updateContext(role: string, content: string): void {
    const tokens = Math.ceil(content.length / 4);
    this.conversationContext.push({ role, content, tokens });
    this.totalTokens += tokens;
    
    // Context limit kontrolÃ¼
    while (this.totalTokens > this.MAX_CONTEXT_LENGTH && this.conversationContext.length > 1) {
      const removed = this.conversationContext.shift();
      if (removed?.tokens) {
        this.totalTokens -= removed.tokens;
      }
    }
  }

  private displayContextInfo(): void {
    const percentage = ((this.totalTokens / this.MAX_CONTEXT_LENGTH) * 100).toFixed(1);
    const color = this.totalTokens > this.MAX_CONTEXT_LENGTH * 0.8 ? 'red' : 
                  this.totalTokens > this.MAX_CONTEXT_LENGTH * 0.6 ? 'yellow' : 'green';
    
    console.log(chalk[color](`ğŸ§  Context: ${this.totalTokens.toLocaleString()}/${this.MAX_CONTEXT_LENGTH.toLocaleString()} tokens (${percentage}%)`));
  }
}