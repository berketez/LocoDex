version: '3.8'

# LocoDex DeepSearch - Docker Compose Configuration
# Complete stack for AI-powered research platform

services:
  # Main DeepSearch Application
  deepsearch:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    container_name: locodex-deepsearch
    restart: unless-stopped
    ports:
      - "5000:5000"  # Main API
      - "5001:5001"  # WebSocket
      - "8000:8000"  # Metrics
    environment:
      - FLASK_ENV=production
      - DATABASE_URL=sqlite:///data/deepsearch.db
      - REDIS_URL=redis://redis:6379/0
      - MONGODB_URL=mongodb://mongodb:27017/deepsearch
      - ELASTICSEARCH_URL=http://elasticsearch:9200
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
      - ./config.yaml:/app/config.yaml:ro
    depends_on:
      - redis
      - mongodb
      - elasticsearch
    networks:
      - deepsearch-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Redis Cache
  redis:
    image: redis:7-alpine
    container_name: locodex-redis
    restart: unless-stopped
    ports:
      - "6379:6379"
    command: redis-server --appendonly yes --maxmemory 512mb --maxmemory-policy allkeys-lru
    volumes:
      - redis-data:/data
    networks:
      - deepsearch-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  # MongoDB Document Store
  mongodb:
    image: mongo:7
    container_name: locodex-mongodb
    restart: unless-stopped
    ports:
      - "27017:27017"
    environment:
      - MONGO_INITDB_ROOT_USERNAME=admin
      - MONGO_INITDB_ROOT_PASSWORD=password123
      - MONGO_INITDB_DATABASE=deepsearch
    volumes:
      - mongodb-data:/data/db
      - ./docker/mongodb/init.js:/docker-entrypoint-initdb.d/init.js:ro
    networks:
      - deepsearch-network
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Elasticsearch Full-text Search
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.10.0
    container_name: locodex-elasticsearch
    restart: unless-stopped
    ports:
      - "9200:9200"
      - "9300:9300"
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    networks:
      - deepsearch-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Nginx Reverse Proxy
  nginx:
    image: nginx:alpine
    container_name: locodex-nginx
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./docker/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./docker/nginx/ssl:/etc/nginx/ssl:ro
      - ./src/services/deepsearch/templates:/usr/share/nginx/html:ro
    depends_on:
      - deepsearch
    networks:
      - deepsearch-network
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Prometheus Monitoring
  prometheus:
    image: prom/prometheus:latest
    container_name: locodex-prometheus
    restart: unless-stopped
    ports:
      - "9090:9090"
    volumes:
      - ./docker/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    networks:
      - deepsearch-network

  # Grafana Dashboards
  grafana:
    image: grafana/grafana:latest
    container_name: locodex-grafana
    restart: unless-stopped
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin123
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana-data:/var/lib/grafana
      - ./docker/grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./docker/grafana/datasources:/etc/grafana/provisioning/datasources:ro
    depends_on:
      - prometheus
    networks:
      - deepsearch-network

  # Jaeger Tracing
  jaeger:
    image: jaegertracing/all-in-one:latest
    container_name: locodex-jaeger
    restart: unless-stopped
    ports:
      - "16686:16686"
      - "14268:14268"
    environment:
      - COLLECTOR_OTLP_ENABLED=true
    networks:
      - deepsearch-network

  # Celery Worker for Background Tasks
  celery-worker:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    container_name: locodex-celery-worker
    restart: unless-stopped
    command: celery -A src.services.deepsearch.core worker --loglevel=info --concurrency=4
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/1
      - CELERY_RESULT_BACKEND=redis://redis:6379/1
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
      - ./config.yaml:/app/config.yaml:ro
    depends_on:
      - redis
      - deepsearch
    networks:
      - deepsearch-network

  # Celery Beat Scheduler
  celery-beat:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    container_name: locodex-celery-beat
    restart: unless-stopped
    command: celery -A src.services.deepsearch.core beat --loglevel=info
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/1
      - CELERY_RESULT_BACKEND=redis://redis:6379/1
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
      - ./config.yaml:/app/config.yaml:ro
    depends_on:
      - redis
      - deepsearch
    networks:
      - deepsearch-network

  # Flower Celery Monitoring
  flower:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    container_name: locodex-flower
    restart: unless-stopped
    ports:
      - "5555:5555"
    command: celery -A src.services.deepsearch.core flower --port=5555
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/1
      - CELERY_RESULT_BACKEND=redis://redis:6379/1
    depends_on:
      - redis
      - celery-worker
    networks:
      - deepsearch-network

  # Backup Service
  backup:
    image: alpine:latest
    container_name: locodex-backup
    restart: unless-stopped
    volumes:
      - ./data:/backup/data:ro
      - ./backups:/backup/output
      - ./docker/backup/backup.sh:/backup.sh:ro
    command: sh -c "while true; do /backup.sh; sleep 86400; done"
    networks:
      - deepsearch-network

  # Log Aggregation with Fluentd
  fluentd:
    image: fluent/fluentd:v1.16-debian-1
    container_name: locodex-fluentd
    restart: unless-stopped
    ports:
      - "24224:24224"
      - "24224:24224/udp"
    volumes:
      - ./docker/fluentd/fluent.conf:/fluentd/etc/fluent.conf:ro
      - ./logs:/var/log/locodex
    networks:
      - deepsearch-network

  # MinIO Object Storage (for file uploads)
  minio:
    image: minio/minio:latest
    container_name: locodex-minio
    restart: unless-stopped
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      - MINIO_ROOT_USER=minioadmin
      - MINIO_ROOT_PASSWORD=minioadmin123
    volumes:
      - minio-data:/data
    command: server /data --console-address ":9001"
    networks:
      - deepsearch-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3

  # Watchtower for Auto-updates
  watchtower:
    image: containrrr/watchtower:latest
    container_name: locodex-watchtower
    restart: unless-stopped
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      - WATCHTOWER_CLEANUP=true
      - WATCHTOWER_POLL_INTERVAL=3600
      - WATCHTOWER_INCLUDE_STOPPED=true
    command: --interval 3600 --cleanup

# Networks
networks:
  deepsearch-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

# Volumes
volumes:
  redis-data:
    driver: local
  mongodb-data:
    driver: local
  elasticsearch-data:
    driver: local
  prometheus-data:
    driver: local
  grafana-data:
    driver: local
  minio-data:
    driver: local

# Development Override
# Use: docker-compose -f docker-compose.yml -f docker-compose.dev.yml up
---
version: '3.8'

# Development overrides
services:
  deepsearch:
    build:
      target: development
    environment:
      - FLASK_ENV=development
      - FLASK_DEBUG=1
    volumes:
      - .:/app
      - /app/node_modules
    ports:
      - "5000:5000"
      - "5001:5001"
      - "8000:8000"
      - "5678:5678"  # Debugger port

  # Development database with sample data
  mongodb:
    volumes:
      - ./docker/mongodb/dev-init.js:/docker-entrypoint-initdb.d/dev-init.js:ro

  # Hot reload for development
  nginx:
    volumes:
      - ./src/services/deepsearch/templates:/usr/share/nginx/html:ro

