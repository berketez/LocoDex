import asyncio
import json
import subprocess
import time
import requests
import websockets
import sys
import os
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor
from rich.console import Console
from rich.markdown import Markdown
from rich.panel import Panel
from rich.prompt import Prompt, IntPrompt
from rich.spinner import Spinner

async def async_input(prompt_text):
    """Async input wrapper"""
    loop = asyncio.get_event_loop()
    executor = ThreadPoolExecutor(max_workers=1)
    
    def sync_input():
        console = Console()
        return Prompt.ask(prompt_text)
    
    try:
        result = await loop.run_in_executor(executor, sync_input)
        return result
    except (KeyboardInterrupt, EOFError):
        return None

def find_locodex_project_dir():
    """LocoDex proje dizinini bul"""
    current_dir = Path.cwd()
    
    # Ã–nce mevcut dizini kontrol et
    if (current_dir / 'docker-compose.yml').exists():
        return current_dir
    
    # YaygÄ±n konumlarÄ± kontrol et
    possible_locations = [
        Path.home() / 'Desktop' / 'LocoDex-Final',
        Path.home() / 'Documents' / 'LocoDex-Final',
        Path.home() / 'LocoDex-Final',
        Path('/Users') / os.getenv('USER', 'user') / 'Desktop' / 'LocoDex-Final',
    ]
    
    for location in possible_locations:
        if location.exists() and (location / 'docker-compose.yml').exists():
            return location
    
    return None

def check_docker_services():
    """Docker servislerini kontrol et ve gerekirse baÅŸlat"""
    console = Console()
    
    # LocoDex proje dizinini bul
    project_dir = find_locodex_project_dir()
    if not project_dir:
        console.print("[bold red]âŒ LocoDex proje dizini bulunamadÄ±![/bold red]")
        console.print("LÃ¼tfen LocoDex-Final dizininde Ã§alÄ±ÅŸtÄ±rÄ±n veya dizin yolunu kontrol edin.")
        return False
    
    # Proje dizinine geÃ§
    original_dir = os.getcwd()
    os.chdir(project_dir)
    
    try:
        # Docker servislerinin durumunu kontrol et
        result = subprocess.run(['docker-compose', 'ps', '--services', '--filter', 'status=running'], 
                              capture_output=True, text=True, check=True)
        running_services = result.stdout.strip().split('\n') if result.stdout.strip() else []
        
        if 'deep-research-service' not in running_services:
            console.print("ğŸ”„ Docker servisleri baÅŸlatÄ±lÄ±yor...")
            
            # Docker servislerini baÅŸlat
            with console.status("[bold blue]Docker Compose servisleri baÅŸlatÄ±lÄ±yor...[/bold blue]") as status:
                result = subprocess.run(['docker-compose', 'up', '-d'], 
                                      capture_output=True, text=True)
                
                if result.returncode != 0:
                    console.print(f"[bold red]Docker servisleri baÅŸlatÄ±lamadÄ±:[/bold red] {result.stderr}")
                    return False
            
            console.print("âœ… Docker servisleri baÅŸlatÄ±ldÄ±!")
            
            # Servislerin hazÄ±r olmasÄ±nÄ± bekle
            with console.status("[bold blue]Servisler hazÄ±rlanÄ±yor...[/bold blue]"):
                time.sleep(10)  # Servislerin baÅŸlamasÄ± iÃ§in bekle
                
        else:
            console.print("âœ… Docker servisleri zaten Ã§alÄ±ÅŸÄ±yor!")
            
        return True
        
    except subprocess.CalledProcessError as e:
        console.print(f"[bold red]Docker komutu baÅŸarÄ±sÄ±z:[/bold red] {e}")
        return False
    except FileNotFoundError:
        console.print("[bold red]Docker Compose bulunamadÄ±! LÃ¼tfen Docker'Ä± yÃ¼kleyin.[/bold red]")
        return False
    finally:
        # Orijinal dizine geri dÃ¶n
        os.chdir(original_dir)

def get_available_models():
    """Mevcut modelleri hem Ollama hem de LM Studio'dan al"""
    models = []
    
    # Ollama'dan modelleri al
    try:
        response = requests.get("http://localhost:11434/api/tags", timeout=5)
        if response.status_code == 200:
            ollama_models = response.json().get('models', [])
            for model in ollama_models:
                models.append({"id": model['name'], "source": "Ollama"})
    except:
        pass

    # LM Studio'dan modelleri al
    try:
        response = requests.get("http://localhost:1234/v1/models", timeout=5)
        if response.status_code == 200:
            lm_studio_models = response.json().get('data', [])
            for model in lm_studio_models:
                models.append({"id": model['id'], "source": "LM Studio"})
    except:
        pass
        
    return models

def select_model():
    """KullanÄ±cÄ±nÄ±n model seÃ§mesini saÄŸla"""
    console = Console()
    
    # Mevcut modelleri al
    models = get_available_models()
    
    if not models:
        console.print("âš  [yellow]Aktif model bulunamadÄ±. LÃ¼tfen Ollama veya LM Studio'nun Ã§alÄ±ÅŸtÄ±ÄŸÄ±ndan emin olun.[/yellow]")
        return None
    
    console.print("\nğŸ¤– [bold cyan]Mevcut AI Modelleri:[/bold cyan]")
    for i, model in enumerate(models, 1):
        console.print(f"  {i}. {model['id']} ({model['source']})")
    
    try:
        choice_str = Prompt.ask(
            f"Kullanmak istediÄŸiniz modelin numarasÄ±nÄ± seÃ§in (enter = 1. model)",
            default="1"
        )
        
        try:
            choice = int(choice_str)
            if 1 <= choice <= len(models):
                selected_model = models[choice - 1]
                console.print(f"âœ“ [green]{selected_model['id']} modeli seÃ§ildi![/green]")
                return selected_model
            else:
                console.print("âš  GeÃ§ersiz seÃ§im, varsayÄ±lan model kullanÄ±lacak.")
                return models[0] if models else None
        except ValueError:
            console.print("âš  GeÃ§ersiz giriÅŸ, varsayÄ±lan model kullanÄ±lacak.")
            return models[0] if models else None
            
    except (KeyboardInterrupt, EOFError):
        console.print("\nâš  Model seÃ§imi iptal edildi, varsayÄ±lan model kullanÄ±lacak.")
        return models[0] if models else None


async def main():
    console = Console()
    console.print("ğŸ¤– [bold cyan]LocoDex Deep Research CLI BaÅŸlatÄ±lÄ±yor...[/bold cyan]\n")
    
    # Docker servislerini kontrol et ve baÅŸlat
    if not check_docker_services():
        console.print("\nğŸ’¡ LÃ¼tfen Docker'Ä±n Ã§alÄ±ÅŸtÄ±ÄŸÄ±ndan emin olun ve tekrar deneyin.")
        return

    # Model seÃ§
    selected_model = select_model()
    
    if not selected_model:
        console.print("\n[bold red]âŒ Model seÃ§ilmeden devam edilemez. Ã‡Ä±kÄ±lÄ±yor.[/bold red]")
        return

    # Model seÃ§imi sÄ±rasÄ±nda model hazÄ±r durumunu kontrol et
    with console.status(f"[bold blue]{selected_model['id']} modeli kontrol ediliyor..."):
        time.sleep(2)
    console.print(f"âœ” âœ“ {selected_model['id']} modeli hazÄ±r ve kullanÄ±ma uygun!")

    console.print("ğŸŒŸ [bold cyan]Deep Search ModÃ¼lÃ¼ Aktif![/bold cyan]")
    console.print("   Yapay zeka destekli derinlemesine araÅŸtÄ±rma yapmaya hazÄ±rlanÄ±yor...")
    console.print("   ğŸ’¡ Ä°pucu: Ã‡Ä±kmak iÃ§in \"exit\" yazÄ±n\n")

    uri = "ws://localhost:8001/research_ws"

    # Servis baÄŸlantÄ±sÄ±nÄ± dene
    max_retries = 3
    for attempt in range(max_retries):
        try:
            async with websockets.connect(uri) as websocket:
                console.print("âœ” Derin araÅŸtÄ±rma servisine baÅŸarÄ±yla baÄŸlanÄ±ldÄ±!")
                console.print("âœ“ Servis hazÄ±r ve araÅŸtÄ±rma isteklerini bekliyor")

                while True:
                    try:
                        topic = await asyncio.wait_for(
                            async_input("ğŸ”¬ Konu"),
                            timeout=300  # 5 dakika timeout
                        )
                        
                        if topic is None or topic.lower() in ["quit", "exit", "Ã§Ä±k", "Ã§Ä±kÄ±ÅŸ"]:
                            console.print("ğŸ‘‹ Ã‡Ä±kÄ±ÅŸ yapÄ±lÄ±yor...")
                            break

                        await websocket.send(json.dumps({"topic": topic, "model": selected_model}))

                        console.print(f"\nğŸš€ Mesaj gÃ¶nderiliyor: {json.dumps({'topic': topic, 'model': selected_model})}")
                        
                        # Ä°lerleme durumunu basit tek satÄ±rda gÃ¶ster
                        current_status = "BaÅŸlÄ±yor..."
                        
                        with console.status(f"[bold blue]ğŸ”¬ {current_status}[/bold blue]") as status:
                            while True:
                                try:
                                    message_str = await websocket.recv()
                                    message = json.loads(message_str)

                                    if message["type"] == "progress":
                                        # Sadece mesajÄ± gÃ¼ncelle, tek satÄ±rda gÃ¶ster
                                        current_status = message['message']
                                        status.update(f"[bold blue]ğŸ”¬ {current_status}[/bold blue]")
                                    elif message["type"] == "result":
                                        status.stop()
                                        console.print(f"\nğŸ“Š [bold green]AraÅŸtÄ±rma TamamlandÄ±[/bold green]")
                                        console.print(Panel(Markdown(message["data"]), 
                                                            title="[bold green]ğŸ¯ AraÅŸtÄ±rma Sonucu[/bold green]", 
                                                            border_style="green"))
                                        break # Exit the listening loop to ask for new topic
                                    elif message["type"] == "error":
                                        status.stop()
                                        console.print(f"[bold red]âŒ Hata:[/bold red] {message['data']}")
                                        break

                                except websockets.exceptions.ConnectionClosed:
                                    console.print("[bold red]âœ– Derin araÅŸtÄ±rma servisiyle baÄŸlantÄ± kesildi.[/bold red]")
                                    return
                                except json.JSONDecodeError:
                                    console.print("[bold red]âœ– Sunucudan geÃ§ersiz mesaj alÄ±ndÄ±.[/bold red]")
                                    
                    except asyncio.TimeoutError:
                        console.print("â° Zaman aÅŸÄ±mÄ± - 5 dakika boyunca input beklendi.")
                        continue
                    except (KeyboardInterrupt, EOFError):
                        console.print("\nğŸ‘‹ Ã‡Ä±kÄ±ÅŸ yapÄ±lÄ±yor...")
                        return
                        
                return

        except (websockets.exceptions.ConnectionClosedError, ConnectionRefusedError):
            if attempt < max_retries - 1:
                console.print(f"âš  Servis bulunamadÄ±. Yeniden deneniyor... ({attempt + 1}/{max_retries})")
                time.sleep(5)
            else:
                console.print("âœ– Derin araÅŸtÄ±rma servisiyle baÄŸlantÄ± kurulamadÄ±.")
                console.print("âš  Servis bulunamadÄ±. Otomatik olarak baÅŸlatÄ±lÄ±yor...")
                
                # Servisleri yeniden baÅŸlatmayÄ± dene
                if check_docker_services():
                    console.print("ğŸ”„ Servisleri yeniden baÅŸlatÄ±ldÄ±. LÃ¼tfen tekrar deneyin.")
                else:
                    console.print("âœ– Servisler baÅŸlatÄ±lamadÄ± veya baÄŸlantÄ± yine baÅŸarÄ±sÄ±z oldu.")
                    console.print("\nğŸ’¡ LÃ¼tfen Docker'Ä±n Ã§alÄ±ÅŸtÄ±ÄŸÄ±ndan emin olun ve tekrar deneyin.")
                    console.print("   Hata detayÄ±: Command failed: docker-compose up -d")

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nğŸ‘‹ LocoDex Deep Research CLI kapatÄ±lÄ±yor...")
    except Exception as e:
        print(f"\nâŒ Beklenmeyen hata: {e}")
        print("LÃ¼tfen tekrar deneyin veya destek alÄ±n.")